{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a01002e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data cleaning et programmation method chaining (pandas)\n",
    "\n",
    "**Francis Wolinski**\n",
    "\n",
    "Consultant scientifique indépendant depuis 2013, bénéficiaire du programme résidentiel de **datacraft**\n",
    "- Audit, Conseil et Projets en Data Science\n",
    "- Formations professionnelles sur le langage Python pour la Data Science\n",
    "- Responsable d'un MSc en IA à SKEMA\n",
    "\n",
    "Juin 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a132c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan\n",
    "\n",
    "Cet atelier reprend l'essentiel de l'atelier donné en février 2022 avec une partie supplémentaire sur la préparation des données.\n",
    "\n",
    "1. **Introduction**\n",
    "2. **Programmation avec pandas**\n",
    "3. **Chargement des données**\n",
    "4. **Data Preparation** <span style=\"color:orange;font-weight:bold\">&starf; NEW &starf;</span>\n",
    "5. **Autres datasets**\n",
    "6. **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf202b2-e70b-4eb3-b578-0f1f8ac62ad3",
   "metadata": {},
   "source": [
    "Librairies et versions utilisées dans ce notebook :\n",
    "- **IPython** 8.13.2\n",
    "- **numpy** 1.24.3\n",
    "- **pandas** 2.0.1\n",
    "- **matplotlib** 3.7.1\n",
    "- **sparklines** 0.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287356f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "L'objectif de cet atelier n'est pas d'effectuer une introduction à **pandas** mais plutôt de présenter quelques caractéristiques de la librairie, ainsi que les enseignements tirés d'une utilisation intensive et dans de nombreux contextes depuis 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdf3b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Méthodologie CRISP-DM**\n",
    "\n",
    "**CR**oss-**I**ndustry **S**tandard **P**rocess for **D**ata **M**ining\n",
    "\n",
    "Etablie par la société SPSS (Statistical Package for the Social Sciences) en 2000 qui a été rachetée par IBM en 2009.\n",
    "\n",
    "A noter : le logiciel SPSS est un peu l'ancêtre de dataiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a10b94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load image from pandas books\n",
    "from IPython.display import Image\n",
    "\n",
    "# load CRISP-DM\n",
    "Image(\"images/schema-crisp-dm.png\", width=960, height=532)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f61d329",
   "metadata": {},
   "source": [
    "La librairie **pandas** peut être notamment mise en oeuvre dans les processus : *Data Understanding*, *Data Preparation* et aussi *Modeling* (directement et indirectement via **matplotlib**, **scikit-learn** et autres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f74905",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# load CRISP-DM\n",
    "Image(\"images/process-crisp-dm.png\", width=960, height=532)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41036487",
   "metadata": {},
   "source": [
    "Source :\n",
    "- *CRISP-DM 1.0 - Step-by-step data mining guide*, 2000, https://www.the-modeling-agency.com/crisp-dm.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e0167-7288-46e3-b5c2-5133220aa1e2",
   "metadata": {},
   "source": [
    "La Data Preparation est souvent la partie la plus chronophage d'un projet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4110e-dfc8-4b35-b9ad-e098061114ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"images/What-data-scientists-spend-the-most-time-doing-7_W640.jpg\", width=640, height=347)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace51e4-19f5-48cb-9969-0cb56df3740d",
   "metadata": {},
   "source": [
    "Source :\n",
    "- *Cleaning Big Data: Most Time-Consuming, Least Enjoyable Data Science Task, Survey Says*, Forbes 2016, https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42a1f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Données de Stack Overflow**\n",
    "\n",
    "**pandas** est sans doute la librairie Python la plus mentionnée dans *Stack Overflow* sur la période 2018-2023.\n",
    "\n",
    "A noter : la baisse de plus de 1% constatée à partir de 2022 correspond à une baisse générale du langage Python sur *Stack Overflow* qui est passé de 17% début 2022 à 14% courant 2023.\n",
    "\n",
    "Sans doute un effet de **CoPilot** et de **ChatGPT** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20ef23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load image from Stack Overflow\n",
    "from IPython.display import SVG\n",
    "\n",
    "display(SVG(\"images/stackoverflow.svg\"))\n",
    "display(SVG(\"images/stackoverflow2.svg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39ef3f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sources :\n",
    "- *pandas: powerful Python data analysis toolkit*, github, 2022, https://github.com/pandas-dev/pandas\n",
    "- Kevin Markham, *What's the future of the pandas library?*, 2018, https://www.dataschool.io/future-of-pandas/\n",
    "- Stack Overflow Trends, https://insights.stackoverflow.com/trends?tags=r%2Cpython\n",
    "- David F. Carr, *Stack Overflow is ChatGPT Casualty: Traffic Down 14% in March*, 2023, https://www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c5456",
   "metadata": {},
   "source": [
    "**ADN de la librarie**\n",
    "\n",
    "Pour mémoire, le nom **PANDAS** vient de l'acronyme **PAN**el (3D) + **DA**taframe (2D) + **S**eries (1D). La classe *Panel* a disparu (dépréciée en 2017 et supprimée en 2019), mais le nom de la librairie a été conservé !\n",
    "\n",
    "Il s'avère que la librairie évolue en permanence (ajouts, modifications, dépréciations) :\n",
    "\n",
    "version | date\n",
    "-|-\n",
    " 0.25 | octobre 2019\n",
    "1.0.0 | janvier 2020\n",
    "1.1.0 | juillet 2020\n",
    "1.2.0 | décembre 2020\n",
    "1.3.0 | juillet 2021\n",
    "1.4.0 | juillet 2022\n",
    "1.5.0 | septembre 2022\n",
    "2.0.0 | avril 2023\n",
    "\n",
    "Les conséquences sont :\n",
    "- Obsolescence rapide des connaissances du data scientist\n",
    "- Nécessité de gérer un environnement virtuel par projet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ad95f-9be8-432c-83b8-1bd72d656006",
   "metadata": {},
   "source": [
    "Pour information, la version **pandas 2.0** sortie récemment apporte un certain nombre de nouveautés dont l'intégration d'un backend supplémentaire possible en remplacement de **NumPy** : *pyarrow* (Apache Arrow).\n",
    "\n",
    "*Using pyarrow means you a speed up and makes for more memory-efficient operations, because you can take advantage of the C++ implementation of Arrow… an open-source and language-agnostic columnar data format to represent data in memory. It can enable zero-copy sharing of data between processes.*\n",
    "\n",
    "*The Apache Arrow in-memory data representation includes an equivalent representation as part of its specification. By using Arrow, pandas is able to deal with missing values without having to implement its own version for each data type.*\n",
    "\n",
    "*PyArrow backed string columns have the potential to impact most workflows in a positive way (...) There is a current proposal in pandas to start inferring strings as PyArrow backed strings by default starting from pandas 3.0.*\n",
    "\n",
    "Sources :\n",
    "- *What’s new in Pandas 2.0?*, Towards Data Science, 2023, https://towardsdatascience.com/whats-new-in-pandas-2-0-5df366eb0197\n",
    "- *Utilizing PyArrow to Improve pandas and Dask Workflows*, Towards Data Science, 2023, https://towardsdatascience.com/utilizing-pyarrow-to-improve-pandas-and-dask-workflows-2891d3d96d2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e98f61",
   "metadata": {},
   "source": [
    "## 2. Programmation avec pandas\n",
    "\n",
    "Avec **pandas**, on est souvent amené à effectuer des séquences d'opérations sur des objets de type *Series* ou *DataFrame*.\n",
    "\n",
    "Il existe plusieurs styles de programmation. Le style en vogue depuis quelques années est le *Method Chaining*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d72a35",
   "metadata": {},
   "source": [
    "### 2.1 Inplace parameter\n",
    "\n",
    "Dans ce style de programmation, on modifie l'objet sur place à chaque étape.\n",
    "\n",
    "```python\n",
    "df.method1(inplace=True)\n",
    "df.method2(inplace=True)\n",
    "df.method3(inplace=True)\n",
    "```\n",
    "\n",
    "> <span style=\"background-color:yellow\">The pandas core team discourages the use of the inplace parameter.</span>\n",
    "\n",
    "En fait, l'utilisation de l'option `inplace=True` ne garantit pas l'absence de copie en mémoire. C'est dû à la gestion de la mémoire par le *BlockManager* qui éclate les données d'un *DataFrame* en autant de *ndarrays* par type de données (int, float, object...).\n",
    "\n",
    "Source :\n",
    "- Uwe Korn, *The one pandas internal I teach all my new colleagues: the BlockManager*, 2020 https://uwekorn.com/2020/05/24/the-one-pandas-internal.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bad2c",
   "metadata": {},
   "source": [
    "### 2.2 Variable assignment\n",
    "\n",
    "Dans ce style de programmation, on affecte à une variable le résultat de chaque opération. Ce style peut conduire à la création de nombreuses variables intermédiaires qui sont peu utilisées.\n",
    "\n",
    "```python\n",
    "df = df.method1()\n",
    "df = df.method2()\n",
    "df = df.method3()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f2d18",
   "metadata": {},
   "source": [
    "### 2.3 Method chaining\n",
    "\n",
    "Dans ce style de programmation, on enchaîne systématiquement les opérations au fur et à mesure sur l'objet qui résulte de l'opération précédente. L'ensemble des enchaînements est encapsulé entre parenthèses pour des raisons syntaxiques.\n",
    "\n",
    "```python\n",
    "(df\n",
    " .method1()\n",
    " .method2()\n",
    " .method3()\n",
    ")\n",
    "```\n",
    "\n",
    "<span style=\"background-color:yellow\">The pandas core team now encourages the use of \"method chaining\"</span>. This is a style of programming in which you chain together multiple method calls into a single statement. This allows you to pass intermediate results from one method to the next rather than storing the intermediate results using variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c1d51",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "- Matt Harrison, *Effective Pandas*, 2021, https://store.metasnake.com/effective-pandas-book\n",
    "\n",
    "- Bindi Chen, *Using Pandas Method Chaining to improve code readability - A tutorial for the best practice with Pandas Method Chaining*,  2020 https://towardsdatascience.com/using-pandas-method-chaining-to-improve-code-readability-d8517c5626ac\n",
    "\n",
    "- Adiamaan Keerthi, *The Unreasonable Effectiveness of Method Chaining in Pandas*, 2019, https://towardsdatascience.com/the-unreasonable-effectiveness-of-method-chaining-in-pandas-15c2109e3c69\n",
    "\n",
    "- Kevin Markham, *What's the future of the pandas library?*, 2018, https://www.dataschool.io/future-of-pandas/\n",
    "\n",
    "- Marc Garcia, *Towards Pandas 1.0*, PyData London Meetup #47, August 2018 https://www.youtube.com/watch?v=hK6o_TDXXN8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9897c6",
   "metadata": {},
   "source": [
    "Il existe des méthodes spéciales qui facilitent ou permettent le chaînage des instructions avec **pandas** en utilisant essentiellement une **notation fonctionnelle** :\n",
    "\n",
    "- **En particulier**\n",
    "    - `s.loc[lambda s_: ...]` ou `df.loc[lambda df_: ...]` : sélections fonctionnelles sur les objets de type *Series* ou *DataFrame* sans avoir à désigner explicitement les objets sur lesquels portent les sélections,\n",
    "    - `df.assign(col=lambda df_: ...)`  ou `assign(**{col=lambda df_: ...})`: utilisation de mot-clés, ou d'un dictionnaire, généralisant l'usage d'une notation fonctionnelle pour modifier ou ajouter des colonnes à un *DataFrame*,\n",
    "    - `s.pipe(func, *args, **kwargs)` ou `df.pipe(func, *args, **kwargs)`: application d'une fonction prenant en premier argument un objet de type *Series* ou *DataFrame*,\n",
    "\n",
    "\n",
    "- **Egalement**\n",
    "    - `eq()`, `ne()`, `gt()`, `ge()`, `lt()`, `le()`... : pour toutes les comparaisons binaires sur les objets de type *Series* ou *DataFrame*,\n",
    "    - `add()`, `sub()`, `mul()`, `div()`, `mod()`, `pow()`... : pour toutes les opérations binaires sur les objets de type *Series* ou *DataFrame*,\n",
    "    - `where(cond, other)` (resp. `mask(cond, other)`) : remplace les valeurs d'un objet de type *Series* ou *DataFrame* si la condition est fausse (resp. vraie).\n",
    "    - `transform(func, *args, **kwargs)` : modification d'un objet de type *Series* ou *DataFrame* par application d'une fonction s'appliquant à chacune de ses valeurs,\n",
    "    - etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e556247",
   "metadata": {},
   "source": [
    "**Remarque** : Pour les *DataFrames*, il est toujours possible d'avoir des noms de colonnes quelconques, mais la notation pousse un peu à utiliser des noms de colonnes utilisables comme attributs. Exemple : `df.col` au lieu de `df[\"col\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959ea28",
   "metadata": {},
   "source": [
    "### 2.4 Un premier exemple\n",
    "\n",
    "On utilise les données de l'Insee sur les prénoms : https://www.insee.fr/fr/statistiques/2540004?sommaire=4767262\n",
    "\n",
    "> Le fichier des prénoms contient des données sur les prénoms attribués aux enfants nés en France entre 1900 et 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3bc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# display options\n",
    "pd.set_option(\"display.min_rows\", 16)\n",
    "pd.set_option(\"display.max_columns\", 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8fcb01",
   "metadata": {},
   "source": [
    "On charge les données et on les prépare en *variable assignment* (qu'on passera en *method chaining* un peu plus loin). On obtient un *DataFrame* avec le nombre de naissances en France par année depuis 1900, par genre et par prénom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process nat2020_csv.zip\n",
    "df_names = pd.read_csv('data/nat2021_csv.zip',\n",
    "                  sep=';',\n",
    "                  header=0,\n",
    "                  names=['gender', 'name', 'year', 'births'],\n",
    "                  na_values={\"name\":\"_PRENOMS_RARES\", \"year\":\"XXXX\"},\n",
    "                  keep_default_na=False)\n",
    "\n",
    "# prep names with variable assignment\n",
    "def prep_names0(df):\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    df = df.loc[df[\"name\"].str.len() > 1]\n",
    "    df[\"gender\"] = df[\"gender\"].map({1:\"M\", 2:\"F\"})\n",
    "    df[\"name\"] = df[\"name\"].str.title()\n",
    "    df = df.astype({'gender':'category', 'year':'uint16', 'births':'uint16'})\n",
    "    df = df[[\"year\", \"name\", \"gender\", \"births\"]]\n",
    "    df = df.sort_values([\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df_names0 = prep_names0(df_names)\n",
    "df_names0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae67c5a",
   "metadata": {},
   "source": [
    "**Exemple résolu**\n",
    "- Graphique avec l'évolution dans le temps de la diversité des prénoms qui se terminent par une lettre donnée, et ce, pour les 7 lettres qui présentent le plus de diversité la dernière année."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23db92",
   "metadata": {},
   "source": [
    "**En variable assignment**\n",
    "\n",
    "En *variable assignment*, on utilise des variables intermédiaires qui sont utilisées peu de fois et qui encombrent la mémoire de Python (*private heap*), et aussi celle du data scientist !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a195cfe-218c-4cc4-8288-1c5f8702ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable assignment\n",
    "df_names1 = df_names0.copy()\n",
    "df_names1['terminal'] = df_names1['name'].apply(lambda x: x[-1].upper())\n",
    "tab = df_names1.pivot_table(values='name',\n",
    "                            index='year',\n",
    "                            columns='terminal',\n",
    "                            aggfunc='count',\n",
    "                            fill_value=0)\n",
    "cols = tab.iloc[-1].nlargest(7).index\n",
    "ax = tab[cols].plot.line(title='Diversité des prénoms par année et par lettre terminale')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df6b79",
   "metadata": {},
   "source": [
    "**En method chaining**\n",
    "\n",
    "Aucune variable intermédiaire n'est utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8be73e-9d4f-4283-8260-4d8b332c38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method chaining\n",
    "(df_names0\n",
    " .assign(terminal=lambda df_: df_.name.apply(lambda x: x[-1].upper()))\n",
    " .pivot_table(values='name',\n",
    "              index='year',\n",
    "              columns='terminal',\n",
    "              aggfunc='count',\n",
    "              fill_value=0)\n",
    " .pipe(lambda df_: df_[df_.iloc[-1].nlargest(7).index])\n",
    " # plot\n",
    " .plot\n",
    " .line(title='Diversité des prénoms par année et par lettre terminale')\n",
    " .legend(bbox_to_anchor=(1.05, 1.0))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5fcf3",
   "metadata": {},
   "source": [
    "**Remarque** : En *method chaining*, on peut facilement afficher et comprendre les calculs intermédiaires en commentant et en décommentant les instructions (et en suprimant le caractère \";\" à la fin)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74297845",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "\n",
    "- Implémenter une fonction en *method chaining* qui produit un graphique avec l'évolution du nombre de naissances d'un prénom et d'un genre au fil des ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e8456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/01_plot_name_gender.py\n",
    "# Graphique avec le nombre de naissances d'un prénom et d'un genre\n",
    "def plot_name_gender(df, name, gender):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b96798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_name_gender\n",
    "plot_name_gender(df_names1, \"Alice\", \"F\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e51016",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "- Passer la fonction `prep_names0` en *method chaining*\n",
    "\n",
    "```python\n",
    "# prep names with variable assignment\n",
    "def prep_names0(df):\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    df = df.loc[df[\"name\"].str.len() > 1]\n",
    "    df[\"gender\"] = df[\"gender\"].map({1:\"M\", 2:\"F\"})\n",
    "    df[\"name\"] = df[\"name\"].str.title()\n",
    "    df = df.astype({'gender':'category', 'year':'uint16', 'births':'uint16'})\n",
    "    df = df[[\"year\", \"name\", \"gender\", \"births\"]]\n",
    "    df = df.sort_values([\"year\", \"gender\", \"births\", \"name\"], ascending=[True, True, False, True])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a701b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/02_prep_names\n",
    "# method chaining\n",
    "def prep_names(df):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26746a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep_names\n",
    "df_names1 = prep_names(df_names)\n",
    "df_names1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838a30a",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "- On a implémenté une fonction qui affiche l'évolution au fil des ans du genre d'un prénom\n",
    "- Passer la fonction `plot_gender_evolution0` en *method chaining*\n",
    "\n",
    "```python\n",
    "# évolution du genre d'un prénom\n",
    "def plot_gender_evolution0(df, name):\n",
    "    selection = df.loc[df['name']==name]\n",
    "    ratio = df.pivot_table(values=\"births\",\n",
    "                           index=\"year\",\n",
    "                           columns=\"gender\",\n",
    "                           aggfunc=\"sum\",\n",
    "                           fill_value=0)\n",
    "    evolution = ratio.div(ratio.sum(axis=1), axis=0)\n",
    "    evolution.plot.line(title=f'Evolution du genre de {name} au fil des ans')\n",
    "```\n",
    "\n",
    "- La tester avec différents prénoms :  *Alix*, *Camille*, *Dominique*, *Charlie*, *Noa*, *Claude*, *Kim*, *Jo*, *George*, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/03_plot_gender_evolution\n",
    "# gender evolution graph for a name\n",
    "def plot_gender_evolution(df, name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gender_evolution(df_names1, \"Camille\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be8061",
   "metadata": {},
   "source": [
    "**Autres exemples (merci à Julien &#9786;)**\n",
    "\n",
    "- Implémenter une fonction qui sélectionne les N prénoms les plus donnés pendant une décennie.\n",
    "- Implémenter une fonction qui produit un graphique avec l'évolution au fil des ans des naissances des N prénoms les plus donnés pendant une décennie. La tester avec différentes périodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/04_top_names_decade.py\n",
    "# Top N prénoms de la décennie\n",
    "def topn_names_decade(df, year, n=5):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_names_decade(df_names1, 1900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062537a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/05_plot_topn_names_decade.py\n",
    "# Top N prénoms de la décennie\n",
    "def plot_topn_names_decade(df, year, n=5):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460280e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decade by decade\n",
    "for year in range(1900, 2020, 10):\n",
    "    plot_topn_names_decade(df_names1, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6dbf3",
   "metadata": {},
   "source": [
    "## 3. Chargement des données\n",
    "\n",
    "Il existe de nombreuses fonctions de chargement des données selon le format d'origine, y compris des formats de logiciels propriétaires ; ce qui a certainement contribué au succès de la librairie.\n",
    "\n",
    "Source : https://pandas.pydata.org/docs/user_guide/io.html\n",
    "\n",
    "Dans le cadre de cet atelier, seule la fonction `read_csv()` sera abordée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ef959",
   "metadata": {},
   "source": [
    "### 3.1 Interprétation automatique des valeurs manquantes\n",
    "\n",
    "Par défaut, en utilisant le backend **NumPy**, la librairie **pandas** interprète automatiquement certaines chaînes de catactères comme étant des valeurs manquantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default NaN values\n",
    "print(pd._libs.parsers.STR_NA_VALUES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb7331",
   "metadata": {},
   "source": [
    "**Remarque** : &#9888; L'interprétation automatique de certaines valeurs peut gêner voir fausser la phase de *Data Understanding*. On va en voir quelques exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d79bb8",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "\n",
    "On charge le dataset des prénoms français avec les valeurs manquantes par défaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load with default missing values\n",
    "df_names1 = pd.read_csv('data/nat2021_csv.zip',\n",
    "                         sep=';')\n",
    "na1 = df_names1.isna().sum()\n",
    "na1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ebcd4",
   "metadata": {},
   "source": [
    "On charge le même dataset avec le type `str` et en neutralisant les valeurs manquantes par défaut (chaîne vide uniquement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff86d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load without missing values except \"\"\n",
    "df_names0 = pd.read_csv('data/nat2021_csv.zip',\n",
    "                  sep=';',\n",
    "                  dtype=str,\n",
    "                  na_values=\"\",\n",
    "                  keep_default_na=False)\n",
    "na0 = df_names0.isna().sum()\n",
    "na0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496e45e",
   "metadata": {},
   "source": [
    "Calcul des écarts entre les nombres de valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# differences of missing values\n",
    "na1 - na0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd8570",
   "metadata": {},
   "source": [
    "Quels noms sont considérés comme des valeurs manquantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which names are interpretted as NaN\n",
    "((df_names0[\"preusuel\"].value_counts() - df_names1[\"preusuel\"].value_counts())\n",
    " .loc[lambda s_: s_ != 0]\n",
    " .index\n",
    " .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0fc093",
   "metadata": {},
   "source": [
    "Dans ce dataset, *NA* est un prénom d'origine chinoise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c348ab64",
   "metadata": {},
   "source": [
    "**Exemples**\n",
    "\n",
    "- On considère le dataset \"cities15000.zip\" : villes mondiales fournies par le site https://www.geonames.org/\n",
    "- Charger ce dataset sans interprétation des valeurs manquantes (à l'exception de la chaîne vide \"\").\n",
    "- Calculer les écarts des nombres de valeurs manquantes entre les 2 *DataFrames*.\n",
    "- Quels sont les \"country_code\" et les \"admin2_code\" qui sont interprétés comme des valeurs manquantes.\n",
    "- Pour les \"admin2_code\" interprétés comme des valeurs manquantes, quels sont les \"country_code\" des pays concernés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3251fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load with default missing values\n",
    "df_cities1 = pd.read_csv('data/cities15000.zip',\n",
    "                         sep='\\t',\n",
    "                         header=None,\n",
    "                         dtype=str,\n",
    "                         names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation', 'dem', 'timezone', 'modification_date'])\n",
    "df_cities1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e73c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/06_missing_values.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6fb4b9",
   "metadata": {},
   "source": [
    "**Conclusion** : En phase de découverte d'un dataset, pour éviter des interprétations erronées, il vaut mieux utiliser de prime abord les trois options :\n",
    "```python\n",
    "dtype=str,\n",
    "na_values=\"\",\n",
    "keep_default_na=False,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790fda9",
   "metadata": {},
   "source": [
    "**Remarque** : Il est possible d'utiliser `functools.partial` pour définir une fonction de chargement des données brutes à partir de la fonction `pandas.read_csv` en fixant certains arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be59a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use functools.partial\n",
    "from functools import partial\n",
    "\n",
    "load_raw_csv = partial(pd.read_csv, dtype=str, na_values=\"\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage of load_raw_csv\n",
    "(load_raw_csv(\"data/nat2021_csv.zip\", sep=\";\")\n",
    " .isna()\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a2682",
   "metadata": {},
   "source": [
    "### 3.2 Visualisation des valeurs manquantes en utilisant la stylisation des *DataFrames*\n",
    "\n",
    "Un *DataFrame* est doté d'un objet *Styler* accessible par l'opérateur `style` qui permet de styliser l'affichage dans un notebook à l'aide de différentes méthodes :\n",
    "- `format({\"col\":\"{:}\")` : formatte les valeurs des cellules,\n",
    "- `bar(color=\"\", subset=cols)` : produit un graphique à barres en fonction de la valeur des cellules numériques indiquées (par ex. \"lightgreen\")\n",
    "- `background_gradient(cmap=\"\", subset=cols)` : utilise une colormap en fonction de la valeur des cellules numériques indiquées (par ex. \"RdYlGn\")\n",
    "- `applymap(func, subset=cols)` : applique une fonction de mise en forme aux cellules en fonction de leur valeur\n",
    "- `pipe(func, *args, **kwargs)` : applique une fonction à l'objet *Styler*.\n",
    "- etc.\n",
    "\n",
    "Couleurs disponibles :\n",
    "- List of named colors: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "- Choosing Colormaps in Matplotlib: https://matplotlib.org/stable/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8b252",
   "metadata": {},
   "source": [
    "**Exemples** :\n",
    "- On charge le fichier \"List0F.zip\". Il s'agit d'un fichier avec les organismes de formation. On va juste s'intéresser au taux de remplissage des différentes colonnes.\n",
    "- A partir du nombre de valeurs non nulles des colonnes, styliser un *DataFrame* avec une barre de couleur.\n",
    "- A partir du pourcentage de remplissage des colonnes arrondi à un chiffre, styliser un *DataFrame* avec une colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ListeOF\n",
    "df_of = load_raw_csv(\"data/ListeOF.zip\")\n",
    "df_of.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb50af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/07_style_bar.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/08_style_cmap.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08395478",
   "metadata": {},
   "source": [
    "### 3.3 Optimisation des types numériques et catégoriels\n",
    "\n",
    "La librairie **pandas** n'optimise pas les types des colonnes chargées. Les types par défaut sont : *int64*, *float64* et *object* pour les chaînes de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e5ff3",
   "metadata": {},
   "source": [
    "**Chargement brut**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cities15000\n",
    "df_cities0 = pd.read_csv('data/cities15000.zip',\n",
    "                   sep='\\t',\n",
    "                   header=None,\n",
    "                   names=['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1_code', 'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation', 'dem', 'timezone', 'modification_date'],\n",
    "                   dtype={'admin1_code': str, 'admin2_code': str, 'admin3_code': str, 'admin4_code': str},\n",
    "                   na_values=['', -9999],\n",
    "                   keep_default_na=False)\n",
    "\n",
    "df_cities0.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd344e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_usage\n",
    "df_cities0.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89771e15",
   "metadata": {},
   "source": [
    "**Optimisation des différents types**\n",
    "\n",
    "On implémente une fonction qui fournit un type minimaliste pour chaque colonne.\n",
    "\n",
    "Evidemment encore faut-il que les valeurs des colonnes ne soient pas ensuite amenées à évoluer et à dépasser les limites des différents types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bbcc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple de dépassement de limite\n",
    "print([i**3 for i in range(10)])\n",
    "\n",
    "# uint8 : 0-255\n",
    "(pd.Series(range(10), dtype='uint8')\n",
    ".pow(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized types\n",
    "def optimized_types(df, n_cats=255):\n",
    "    \"\"\"Return a dict with optimized dtypes for a given DataFrame\"\"\"\n",
    "    \n",
    "    types = {}\n",
    "    \n",
    "    # int\n",
    "    for col in df.select_dtypes(include=['int64']).columns:\n",
    "        \n",
    "        s = df[col]\n",
    "        \n",
    "        # unsigned int\n",
    "        if (s >= 0).all():\n",
    "            for subtype in ['uint8', 'uint16', 'uint32']:  # 'uint64' useless\n",
    "                if (s <= np.iinfo(subtype).max).all():\n",
    "                    types[col] = subtype\n",
    "                    break\n",
    "                    \n",
    "        # signed int\n",
    "        else:\n",
    "            for subtype in ['int8', 'int16', 'int32']:\n",
    "                if ((s >= np.iinfo(subtype).min) & (s <= np.iinfo(subtype).max)).all():\n",
    "                    types[col] = subtype\n",
    "                    break\n",
    "                    \n",
    "    # float\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        \n",
    "        s = df[col].dropna()\n",
    "        \n",
    "        for subtype in ['float16', 'float32']:\n",
    "            if ((s >= np.finfo(subtype).min) & (s <= np.finfo(subtype).max)).all():\n",
    "                types[col] = subtype\n",
    "                break\n",
    "                \n",
    "    # category\n",
    "    types.update({col:\"category\" for col in df.select_dtypes(include=['object']).columns\n",
    "                   if df[col].nunique() <= n_cats})\n",
    "\n",
    "    return types\n",
    "            \n",
    "optimized_types(df_cities0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73120258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory usage\n",
    "df_cities1 = df_cities0.astype(optimized_types(df_cities0))\n",
    "df_cities1.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb05666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_usage\n",
    "df_cities1.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8017af",
   "metadata": {},
   "source": [
    "**Efficacité de la sélection object vs category**\n",
    "\n",
    "La sélection de données catégorielles est plus efficace que celle des chaînes de catactères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_code list\n",
    "df_cities0[\"feature_code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "def tests():\n",
    "    \"\"\"Test speed for different feature_code selection\"\"\"\n",
    "    for code in [\"PPL\", \"PPLA\", \"PPLC\"]:  # cities, administrations level 1, capitals\n",
    "        percent = len(df_cities1.loc[df_cities1[\"feature_code\"]==code])/len(df_cities1)*100\n",
    "        print(f\"{code}: {percent:.1f}%\")\n",
    "        # loc + lambda\n",
    "        %timeit df_cities0.loc[lambda df_: df_.feature_code==code]\n",
    "        %timeit df_cities1.loc[lambda df_: df_.feature_code==code]\n",
    "        print()\n",
    "        \n",
    "# tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b5ba72-9def-4252-967e-b12ad6712d5a",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "L'idée est d'illustrer quelques éléments de Data Preparation avec un dataset. Principalement des opérations de substitution et d'extraction de valeurs.\n",
    "\n",
    "On prend le dataset RH qui avait été utilisé pour la journée AI Act de décembre 2022. Il s'agit de l'enquête annuelle 2022 sur la communauté de *Stack Overflow*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd3781-6652-46f5-80cb-596fe06ce5e0",
   "metadata": {},
   "source": [
    "**Opérations usuelles sur les colonnes**\n",
    "- Explorer un DataFrame :\n",
    "    - info()\n",
    "    - head(), tail(), sample()\n",
    "    - nunique()\n",
    "    - describe()\n",
    "- Explorer les valeurs des colonnes :\n",
    "    - head(), tail(), sample()\n",
    "    - nunique()\n",
    "    - describe()\n",
    "    - unique()\n",
    "    - value_counts(), crosstab()\n",
    "    - sort_index(), sort_values()\n",
    "    - nsmallest(), nlargest()\n",
    "- Lister les colonnes ayant un motif dans leur nom :\n",
    "    - list comprehension : [col for col in df.columns if ...]\n",
    "- Calculer des valeurs à partir d'une colonne existante :\n",
    "    - apply() + lambda ou fonction\n",
    "    - where() et mask()\n",
    "    - str.get_dummies()\n",
    "    - fillna(), dropna()\n",
    "    - map()\n",
    "    - astype() + CategoricalDType\n",
    "    - cut(), qcut()\n",
    "    - replace(), str.replace()\n",
    "    - str.extract()\n",
    "- Non abordé dans cette partie :\n",
    "    - pd.to_numeric()\n",
    "    - pd.to_datetime()\n",
    "    - les opérations logiques, arithmétiques, statistiques et de chaînes de catactères\n",
    "    - combine()\n",
    "    - applymap(), transform()\n",
    " \n",
    "**Autres opérations non traitées**\n",
    "- Reshaping d'un DataFrame :\n",
    "    - set_index(), reset_index(), reindex()\n",
    "    - drop(), drop_duplicates()\n",
    "    - pivot_table(), groupby()\n",
    "    - stack(), unstack(), droplevel(), swaplevel()\n",
    "    - melt()\n",
    "- Combinaison de DataFrames :\n",
    "    - concat()\n",
    "    - merge(), join()\n",
    " \n",
    "*Non exhaustif*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03219d97-4018-4b06-8b4f-352e0708b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72637e-3925-41dd-b778-d848049e4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv(\"data/survey_results_public_2022.zip\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd3c4c-eb77-49c9-b5b2-09408f75c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79 colonnes\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd8f8e-707a-4d7c-a051-b2d95981415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# échantillon des colonnes 1-19\n",
    "\n",
    "np.random.seed(0)\n",
    "df.sample(3).T.loc[:\"CompFreq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50373a3-fce5-4197-a327-093ee45757e9",
   "metadata": {},
   "source": [
    "#### MainBranch\n",
    "\n",
    "**Exploration**\n",
    "- Nombre de valeurs uniques\n",
    "\n",
    "**Tranformation**\n",
    "- *I am a developer by profession* => Dev\n",
    "- \\* => NonDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf88aaa-c06d-4cab-a1c1-b7de3307c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/01_MainBranch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94ecd0-4ad0-411e-8b05-894523e8e30c",
   "metadata": {},
   "source": [
    "#### Employment\n",
    "\n",
    "**Exploration**\n",
    "- Combien y a-t-il de valeurs différentes\n",
    "- Décompte\n",
    "- Décompte en % cummulés\n",
    "\n",
    "**Tranformation**\n",
    "- une colonne par modalité\n",
    "- employed ou not employed\n",
    "- (full time ou part time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8dad8-c2d9-4d10-a1e3-a785fffc76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/02_Employment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0888cd-1e43-462d-8679-8c7d2a3f981b",
   "metadata": {},
   "source": [
    "#### RemoteWork\n",
    "\n",
    "**Exploration**\n",
    "- Effectuer un crosstab entre MainBranch et RemoteWork.\n",
    "\n",
    "**Tranformation**\n",
    "- renommage Remote, Hybrid, Office\n",
    "- passage en données catégorielles ordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef81ba-ae93-4d44-8635-c7ea2ea122be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/03_RemoteWork.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154f35e-7228-4c8e-98c8-f61422437941",
   "metadata": {},
   "source": [
    "#### CodingActivities\n",
    "\n",
    "**Exploration**\n",
    "- Combien y a-t-il de valeurs différentes\n",
    "- Afficher toutes les modalités élémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c81c3-9811-421b-874a-462a0c4877c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/04_CodingActivities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb275e6-e338-4465-8d6d-8893fd895076",
   "metadata": {},
   "source": [
    "#### EdLevel\n",
    "\n",
    "**Transformation**\n",
    "- NoHigherEd, Undergraduate, Master, PhD, Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aabc50-80bb-4ff7-9d01-2fec074a0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/05_EdLevel.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3f137-231b-4d36-91c7-1b55ce055966",
   "metadata": {},
   "source": [
    "#### LearnCode, LearnCodeOnline, LearnCodeCoursesCert\n",
    "\n",
    "**Exploration**\n",
    "- Pour les colonnes débutant par \"LearnCode\", afficher les modalités élémentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4e533-8341-4530-b649-fd067f4baef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/06_LearnCode.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f847ad21-0dee-4c64-88d7-32e18ff0a610",
   "metadata": {},
   "source": [
    "#### (DevType)\n",
    "\n",
    "**Exploration**\n",
    "- Combien y a-t-il de valeurs différentes.\n",
    "- Afficher toutes les modalités élémentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bce13-5ade-4d82-8a0a-cf9f405fa2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/07_DevType.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9001b67c-38ea-4d74-8bb4-b6cdfb695db9",
   "metadata": {},
   "source": [
    "#### OrgSize\n",
    "\n",
    "**Extraction et transformation ($\\star\\star\\star$)**\n",
    "- Passer à des données catégorielles ordonnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085d3f5-2b6f-44e6-885e-e1eaa7e0d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/08_OrgSize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9a8e7-427f-40e7-ba14-8371a694f50a",
   "metadata": {},
   "source": [
    "#### Country\n",
    "\n",
    "**Transformation**\n",
    "- Effectuer un mapping avec les codes ISO3 de la table des pays de geoname : https://www.geonames.org/countries/\n",
    "- Calculer les écarts entre les pays des 2 DataFrames\n",
    "- Appliquer le mapping ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773648c-cdb8-4a93-b9d2-99d5078951be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/09_Country.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b6c3d-97b4-47d3-9512-5361130bee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_country = {\n",
    " 'Brunei Darussalam': 'Brunei',\n",
    " 'Cape Verde': 'Cabo Verde',\n",
    " 'Congo, Republic of the...': 'Congo Republic',\n",
    " 'Czech Republic': 'Czechia',\n",
    " \"Côte d'Ivoire\": 'Ivory Coast',\n",
    " 'Democratic Republic of the Congo': 'DR Congo',\n",
    " 'Gambia': 'The Gambia',\n",
    " 'Hong Kong (S.A.R.)': 'Hong Kong',\n",
    " 'Iran, Islamic Republic of...': 'Iran',\n",
    " \"Lao People's Democratic Republic\": 'Laos',\n",
    " 'Libyan Arab Jamahiriya': 'Libya',\n",
    " 'Nomadic': 'XXX',\n",
    " 'Republic of Korea': 'North Korea',\n",
    " 'Republic of Moldova': 'Moldova',\n",
    " 'Russian Federation': 'Russia',\n",
    " 'Saint Kitts and Nevis': 'St Kitts and Nevis',\n",
    " 'Swaziland': 'Eswatini',\n",
    " 'Syrian Arab Republic': 'Syria',\n",
    " 'The former Yugoslav Republic of Macedonia': 'North Macedonia',\n",
    " 'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n",
    " 'United Republic of Tanzania': 'Tanzania',\n",
    " 'United States of America': 'United States',\n",
    " 'Venezuela, Bolivarian Republic of...': 'Venezuela',\n",
    " 'Viet Nam': 'Vietnam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024ee5f-2ec7-491f-a8a7-e4adf2b3f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# échantillon des colonnes 20-43\n",
    "\n",
    "np.random.seed(0)\n",
    "df.sample(3).T.loc[\"LanguageHaveWorkedWith\":\"OfficeStackSyncWantToWorkWith\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8b8d1-761c-4899-911e-486e6771099d",
   "metadata": {},
   "source": [
    "#### HaveWorkedWith et WantToWorkWith\n",
    "\n",
    "**Transformation et exploration ($\\star\\star$)**\n",
    "- Calculer une série avec le nombre total de mentions de chaque technologie des colonnes HaveWorkedWith\n",
    "- Calculer une série avec le nombre total de mentions de chaque technologie des colonnes WantToWorkWith\n",
    "- Afficher les n plus grandes valeurs du ratio wanttoworkwith / haveworkedwith\n",
    "- Afficher les valeurs pour quelques langages, par exemple : \"Java\", \"C++\", \"Python\", \"Go\", \"Julia\", \"Rust\"\n",
    "- Afficher les valeurs pour les frameworks JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66de97-eb72-45e8-a3f8-e200a628e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/10_Technos.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64745b62-df0a-4af4-a7e9-63e3e704b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# échantillon des colonnes 44-79\n",
    "\n",
    "np.random.seed(0)\n",
    "df.sample(3).T.loc[\"Blockchain\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72623283-ede9-4f35-ad35-0d979be66ec9",
   "metadata": {},
   "source": [
    "#### (Blockchain, SOVisitFreq, SOPartFreq)\n",
    "\n",
    "\n",
    "**Exploration et transformation**\n",
    "- Afficher toutes les modalités.\n",
    "- Passer en variable catégorielle ordonnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc8ed5-cf79-4c16-b1fc-303c961a6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/11_Blockchain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958b5e1-7626-4236-92aa-6c07adcdcae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/12_SOVisitFreq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01261694-3610-4014-a1bf-6cf39ec6a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/13_SOPartFreq.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d99cc-9db1-4282-9b84-5a61905550e7",
   "metadata": {},
   "source": [
    "#### (Age)\n",
    "\n",
    "**Transformation**\n",
    "- Passer à des données catégorielles ordonnées comme pour OrgSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8892ef7-fe56-4ec0-a336-4a2799a73080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/14_Age.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3735a41f-7fec-4602-a72b-077d5c5efea8",
   "metadata": {},
   "source": [
    "#### (Gender)\n",
    "\n",
    "**Explorer**\n",
    "- Analyser les modalités multiples comme pour Employement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569916df-b5ff-4961-8ebb-959ce140818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dataprep/15_Gender.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f4a58",
   "metadata": {},
   "source": [
    "## 5. Autres datasets\n",
    "\n",
    "### 5.1 Taux de change + sparklines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae8a30",
   "metadata": {},
   "source": [
    "Dataset des taux de change fourni par la Banque de France : http://webstat.banque-france.fr/fr/\n",
    "\n",
    "**Chargement du dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af518b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Webstat_Export.csv\n",
    "df_change = pd.read_csv(\"data/Webstat_Export.csv\",\n",
    "                        sep=\";\",\n",
    "                        na_values='-',\n",
    "                        decimal=',',\n",
    "                        skiprows=[1, 2])\n",
    "df_change.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34db72",
   "metadata": {},
   "source": [
    "**Liste des colonnes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "df_change.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08918539",
   "metadata": {},
   "source": [
    "Il est possible d'extraire certains codes ISO3 des devises à l'aide d'une expression régulière."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of currency ISO3\n",
    "(pd.Series(df_change.columns.tolist())\n",
    ".str.extract(r'\\(([A-Z]{3})\\)$', expand=False)\n",
    ".unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be43d18",
   "metadata": {},
   "source": [
    "**Préparation du dataset**\n",
    "\n",
    "On crée une fonction en *variable assignment* pour préparer le dataset et sélectionner quelques devises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071cf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep currency data: variable assignment\n",
    "def prep_change0(df, currencies):\n",
    "    df_prep = df.copy()\n",
    "    cols = pd.Series(df.columns.tolist()).str.extract('\\(([A-Z]{3})\\)$', expand=False)\n",
    "    df_prep.columns = [\"Date\"] + list(cols[1:])\n",
    "    df_prep[\"Date\"] = pd.to_datetime(df_prep[\"Date\"], format='%d/%m/%Y', errors='ignore')\n",
    "    df_prep = df_prep.set_index(\"Date\")\n",
    "    df_prep = df_prep[currencies]\n",
    "    df_prep = df_prep.dropna()\n",
    "    df_prep = df_prep.sort_index()\n",
    "    return df_prep\n",
    "\n",
    "df_change0 = prep_change0(df_change, [\"USD\", \"CHF\", \"GBP\", \"JPY\", \"RUB\", \"CNY\"])\n",
    "df_change0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taux de change spots \n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "((df_change0 / df_change0.iloc[-1])\n",
    " .plot\n",
    " .line(title=\"Taux de change spots\", ax=ax)\n",
    " .legend(bbox_to_anchor=(1.15, 1.0))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ef573",
   "metadata": {},
   "source": [
    "#### Librairie sparklines\n",
    "\n",
    "Une sparkline est une visualisation de données qui représente la forme générale de l'évolution d'une variable sur une ligne. La sparkline est en général insérée dans un texte et dans un tableau.\n",
    "\n",
    "Source : \n",
    "- https://fr.wikipedia.org/wiki/Sparkline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d253ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import sparklines\n",
    "\n",
    "# example\n",
    "print(sparklines.sparklines(pd.Series(range(8)))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce48e0e",
   "metadata": {},
   "source": [
    "On affiche une sparkline donnant l'évolution trimestrielle du dollar en 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# évolution trimestrielle du dollar en 2019\n",
    "tab = (df_change0\n",
    "       .loc[\"2019\", \"USD\"]\n",
    "       .resample('Q')\n",
    "       .mean()\n",
    "      )\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79baa171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparkline donnant l'évolution trimestrielle du dollar en 2019\n",
    "print(sparklines.sparklines(tab)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789fbc28",
   "metadata": {},
   "source": [
    "Il est possible de simplifier l'API de sparklines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparkl\n",
    "def sparkl(series):\n",
    "    \"\"\"Return a sparkline string for the given Series object\"\"\"\n",
    "    return sparklines.sparklines(series)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkl(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe47fa",
   "metadata": {},
   "source": [
    "**Exemples**\n",
    "- Passer la fonction `prep_change0` en *method chaining*.\n",
    "- Modifier le graphique en divisant les taux de change a) par leurs moyennes respectives b) par leurs dernières valeurs respectives.\n",
    "- Vérifier que le graphique \"fonctionne\" lorsqu'on restreint la période temporelle considérée (par ex. `loc[\"2019\":\"2020\"]`).\n",
    "- Faire un graphique avec les taux de change divisés par leur moyennes respectives a) avec une moyenne mobile de 30 jours b) avec un maximum mobile de 100 jours.\n",
    "- Produire un *DataFrame* avec les moyennes annuelles du cours du dollar (par exemple) arrondies à 3 décimales et des sparklines donnant les tendances trimestrielles.\n",
    "- Rajouter un style pour que les moyennes annuelles apparaissent en vert si elles sont supérieures à 1.0 et en rouge sinon.\n",
    "- Ecrire une fonction qui pour une année donnée produit un *DataFrame* avec les moyennes annuelles des cours des différentes devises et des sparklines donnant leurs tendances trimestrielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd9a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/09_prep_change\n",
    "def prep_change(df, currencies):\n",
    "\n",
    "    pass\n",
    "\n",
    "df_change1 = prep_change(df_change, [\"USD\", \"CHF\", \"GBP\", \"JPY\", \"RUB\", \"CNY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b4cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/10_plot_change.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114fc91",
   "metadata": {},
   "source": [
    "### 5.2 Online Retail\n",
    "\n",
    "Dataset *Online Retail* de Kaggle : https://www.kaggle.com/vijayuv/onlineretail\n",
    "\n",
    "- Ela Kapoor, *Time series and feature engg analysis for retail*, (2021) https://www.kaggle.com/elakapoor/time-series-and-feature-engg-analysis-for-retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152f42e",
   "metadata": {},
   "source": [
    "**Exemples**\n",
    "- Charger le dataset avec la fonction `load_raw_csv` et vérifier les valeurs manquantes.\n",
    "- Ecrire une fonction de préparation du dataset :\n",
    "    - suppression des lignes dupliquées\n",
    "    - utiliser des types optimisés pour \"Quantity\" et \"UnitPrice\" (float32)\n",
    "    - convertir \"InvoiceDate\" en date\n",
    "- Faire un graphique à barres avec les volumes des transactions selon les heures\n",
    "- Faire des graphiques à secteurs avec les volumes et les montants des transactions \"UK\" / \"Non UK\"\n",
    "- Faire des graphiques à barres avec les volumes et les montants des transactions par pays \"Non UK\"\n",
    "- Faire des graphiques à barres avec les volumes et les montants des transactions par type \"Purchase\" (Quantity &geq; 0) ou \"Return\" (Quantity &lt; 0)\n",
    "- Produire un *DataFrame* avec les moyennes des montants des transactions par pays arrondies à 2 décimales triées par ordre décroissant et des sparklines donnant les tendances trimestrielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eecd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw CSV\n",
    "df_or = load_raw_csv(\"data/OnlineRetail.csv.zip\", encoding='unicode_escape')\n",
    "df_or.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b35af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/11_prep_retail.py\n",
    "\n",
    "def prep_retail(df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c890767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load exemples/12_plot_retail.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88b0f8",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "Voir si la *Method chaining* tient ses promesses :\n",
    "- Normaliser l'écriture du code avec **pandas**\n",
    "- Faciliter la compréhension et la maintenance du code\n",
    "- Optimiser l'utilisation de la mémoire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1fa89-c096-4b24-b6f3-26558a65b1c4",
   "metadata": {},
   "source": [
    "<div>\n",
    "<h1 style=\"font-weight: bold; font-style: italic; margin: 10px; color: rgb(231, 4, 136);\">pynk</h1>\n",
    "\n",
    "**write better pandas code**\n",
    "\n",
    "https://pynk.yotta-conseil.fr\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
